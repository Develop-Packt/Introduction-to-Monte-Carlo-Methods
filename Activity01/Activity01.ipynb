{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"FrozenLake-v0\", is_slippery=False)\n",
    "env.reset()                    \n",
    "env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discrete(16)\n",
      "Discrete(4)\n"
     ]
    }
   ],
   "source": [
    "print(env.observation_space)\n",
    "print(env.action_space)\n",
    "name_action = {0:'Left',1:'Down',2:'Right',3:'Up'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_frozenlake_episode():\n",
    "    episode = []\n",
    "    state = env.reset()\n",
    "    step = 0;\n",
    "    \n",
    "    while (True):\n",
    "        action = env.action_space.sample()\n",
    "        next_state, reward, done, info = env.step(action)\n",
    "        episode.append((next_state, action, reward))\n",
    "        if done:\n",
    "            break\n",
    "        state = next_state\n",
    "        step += 1\n",
    "    return episode, reward     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frozen_lake_prediction(batch):\n",
    "    for batch_number in range(batch+1):\n",
    "        total_reward = 0\n",
    "        for i_episode in range(100):\n",
    "            \n",
    "            episode, reward = generate_frozenlake_episode()\n",
    "            total_reward += reward\n",
    "        success_percent = total_reward/100\n",
    "        print(\"Episode\", batch_number*100, \"Policy Win Rate=>\", float(success_percent*100), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0 Policy Win Rate=> 1.0 %\n",
      "Episode 100 Policy Win Rate=> 1.0 %\n",
      "Episode 200 Policy Win Rate=> 1.0 %\n",
      "Episode 300 Policy Win Rate=> 2.0 %\n",
      "Episode 400 Policy Win Rate=> 1.0 %\n",
      "Episode 500 Policy Win Rate=> 0.0 %\n",
      "Episode 600 Policy Win Rate=> 1.0 %\n",
      "Episode 700 Policy Win Rate=> 1.0 %\n",
      "Episode 800 Policy Win Rate=> 2.0 %\n",
      "Episode 900 Policy Win Rate=> 0.0 %\n",
      "Episode 1000 Policy Win Rate=> 0.0 %\n",
      "Episode 1100 Policy Win Rate=> 2.0 %\n",
      "Episode 1200 Policy Win Rate=> 0.0 %\n",
      "Episode 1300 Policy Win Rate=> 0.0 %\n",
      "Episode 1400 Policy Win Rate=> 7.000000000000001 %\n",
      "Episode 1500 Policy Win Rate=> 2.0 %\n",
      "Episode 1600 Policy Win Rate=> 2.0 %\n",
      "Episode 1700 Policy Win Rate=> 0.0 %\n",
      "Episode 1800 Policy Win Rate=> 2.0 %\n",
      "Episode 1900 Policy Win Rate=> 1.0 %\n",
      "Episode 2000 Policy Win Rate=> 0.0 %\n",
      "Episode 2100 Policy Win Rate=> 3.0 %\n",
      "Episode 2200 Policy Win Rate=> 3.0 %\n",
      "Episode 2300 Policy Win Rate=> 1.0 %\n",
      "Episode 2400 Policy Win Rate=> 2.0 %\n",
      "Episode 2500 Policy Win Rate=> 3.0 %\n",
      "Episode 2600 Policy Win Rate=> 1.0 %\n",
      "Episode 2700 Policy Win Rate=> 2.0 %\n",
      "Episode 2800 Policy Win Rate=> 0.0 %\n",
      "Episode 2900 Policy Win Rate=> 2.0 %\n",
      "Episode 3000 Policy Win Rate=> 0.0 %\n",
      "Episode 3100 Policy Win Rate=> 1.0 %\n",
      "Episode 3200 Policy Win Rate=> 2.0 %\n",
      "Episode 3300 Policy Win Rate=> 3.0 %\n",
      "Episode 3400 Policy Win Rate=> 4.0 %\n",
      "Episode 3500 Policy Win Rate=> 2.0 %\n",
      "Episode 3600 Policy Win Rate=> 2.0 %\n",
      "Episode 3700 Policy Win Rate=> 0.0 %\n",
      "Episode 3800 Policy Win Rate=> 1.0 %\n",
      "Episode 3900 Policy Win Rate=> 0.0 %\n",
      "Episode 4000 Policy Win Rate=> 2.0 %\n",
      "Episode 4100 Policy Win Rate=> 2.0 %\n",
      "Episode 4200 Policy Win Rate=> 1.0 %\n",
      "Episode 4300 Policy Win Rate=> 2.0 %\n",
      "Episode 4400 Policy Win Rate=> 3.0 %\n",
      "Episode 4500 Policy Win Rate=> 0.0 %\n",
      "Episode 4600 Policy Win Rate=> 0.0 %\n",
      "Episode 4700 Policy Win Rate=> 2.0 %\n",
      "Episode 4800 Policy Win Rate=> 1.0 %\n",
      "Episode 4900 Policy Win Rate=> 0.0 %\n",
      "Episode 5000 Policy Win Rate=> 1.0 %\n",
      "Episode 5100 Policy Win Rate=> 0.0 %\n",
      "Episode 5200 Policy Win Rate=> 1.0 %\n",
      "Episode 5300 Policy Win Rate=> 0.0 %\n",
      "Episode 5400 Policy Win Rate=> 3.0 %\n",
      "Episode 5500 Policy Win Rate=> 2.0 %\n",
      "Episode 5600 Policy Win Rate=> 1.0 %\n",
      "Episode 5700 Policy Win Rate=> 2.0 %\n",
      "Episode 5800 Policy Win Rate=> 2.0 %\n",
      "Episode 5900 Policy Win Rate=> 0.0 %\n",
      "Episode 6000 Policy Win Rate=> 5.0 %\n",
      "Episode 6100 Policy Win Rate=> 1.0 %\n",
      "Episode 6200 Policy Win Rate=> 1.0 %\n",
      "Episode 6300 Policy Win Rate=> 1.0 %\n",
      "Episode 6400 Policy Win Rate=> 1.0 %\n",
      "Episode 6500 Policy Win Rate=> 1.0 %\n",
      "Episode 6600 Policy Win Rate=> 2.0 %\n",
      "Episode 6700 Policy Win Rate=> 1.0 %\n",
      "Episode 6800 Policy Win Rate=> 2.0 %\n",
      "Episode 6900 Policy Win Rate=> 2.0 %\n",
      "Episode 7000 Policy Win Rate=> 2.0 %\n",
      "Episode 7100 Policy Win Rate=> 1.0 %\n",
      "Episode 7200 Policy Win Rate=> 2.0 %\n",
      "Episode 7300 Policy Win Rate=> 2.0 %\n",
      "Episode 7400 Policy Win Rate=> 1.0 %\n",
      "Episode 7500 Policy Win Rate=> 1.0 %\n",
      "Episode 7600 Policy Win Rate=> 0.0 %\n",
      "Episode 7700 Policy Win Rate=> 1.0 %\n",
      "Episode 7800 Policy Win Rate=> 3.0 %\n",
      "Episode 7900 Policy Win Rate=> 2.0 %\n",
      "Episode 8000 Policy Win Rate=> 0.0 %\n",
      "Episode 8100 Policy Win Rate=> 3.0 %\n",
      "Episode 8200 Policy Win Rate=> 1.0 %\n",
      "Episode 8300 Policy Win Rate=> 1.0 %\n",
      "Episode 8400 Policy Win Rate=> 2.0 %\n",
      "Episode 8500 Policy Win Rate=> 1.0 %\n",
      "Episode 8600 Policy Win Rate=> 1.0 %\n",
      "Episode 8700 Policy Win Rate=> 2.0 %\n",
      "Episode 8800 Policy Win Rate=> 0.0 %\n",
      "Episode 8900 Policy Win Rate=> 1.0 %\n",
      "Episode 9000 Policy Win Rate=> 2.0 %\n",
      "Episode 9100 Policy Win Rate=> 2.0 %\n",
      "Episode 9200 Policy Win Rate=> 1.0 %\n",
      "Episode 9300 Policy Win Rate=> 1.0 %\n",
      "Episode 9400 Policy Win Rate=> 0.0 %\n",
      "Episode 9500 Policy Win Rate=> 2.0 %\n",
      "Episode 9600 Policy Win Rate=> 1.0 %\n",
      "Episode 9700 Policy Win Rate=> 1.0 %\n",
      "Episode 9800 Policy Win Rate=> 2.0 %\n",
      "Episode 9900 Policy Win Rate=> 1.0 %\n",
      "Episode 10000 Policy Win Rate=> 1.0 %\n"
     ]
    }
   ],
   "source": [
    "frozen_lake_prediction(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
